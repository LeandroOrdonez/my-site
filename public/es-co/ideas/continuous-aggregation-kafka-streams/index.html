<!doctype html><html lang=es-co>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=content-language content="es-co">
<meta name=author content="Leandro Ordóñez Ante">
<meta name=description content="Lago el Bolsón in Popayán, Colombia, my home town :)
  In this post I show a method to address the computation of the arithmetic mean of an stream of values (say sensor readings) using the Kafka Streams DSL. The estimation of the average in a stream processing setting implies keeping track of other two measurements, namely the count of incoming records and the sum of their corresponding values.">
<meta name=keywords content="blog,desarrollador,personal">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Continuous aggregation in Kafka Streams">
<meta name=twitter:description content="Lago el Bolsón in Popayán, Colombia, my home town :)
  In this post I show a method to address the computation of the arithmetic mean of an stream of values (say sensor readings) using the Kafka Streams DSL. The estimation of the average in a stream processing setting implies keeping track of other two measurements, namely the count of incoming records and the sum of their corresponding values.">
<meta property="og:title" content="Continuous aggregation in Kafka Streams">
<meta property="og:description" content="Lago el Bolsón in Popayán, Colombia, my home town :)
  In this post I show a method to address the computation of the arithmetic mean of an stream of values (say sensor readings) using the Kafka Streams DSL. The estimation of the average in a stream processing setting implies keeping track of other two measurements, namely the count of incoming records and the sum of their corresponding values.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://leandro.ordonez.tech/es-co/ideas/continuous-aggregation-kafka-streams/"><meta property="article:section" content="ideas">
<meta property="article:published_time" content="2019-10-17T10:45:27+02:00">
<meta property="article:modified_time" content="2019-10-17T10:45:27+02:00">
<base href=https://leandro.ordonez.tech/es-co/ideas/continuous-aggregation-kafka-streams/>
<title>
Continuous aggregation in Kafka Streams · Leandro Ordóñez Ante
</title><link rel=canonical href=https://leandro.ordonez.tech/es-co/ideas/continuous-aggregation-kafka-streams/>
<link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel=stylesheet>
<link rel=stylesheet href=https://use.fontawesome.com/releases/v5.13.0/css/all.css integrity=sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V crossorigin=anonymous>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin=anonymous>
<link rel=stylesheet href=https://leandro.ordonez.tech/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin=anonymous media=screen>
<link rel=stylesheet href=https://leandro.ordonez.tech/css/custom.css>
<link rel=icon type=image/png href=https://leandro.ordonez.tech/images/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=https://leandro.ordonez.tech/images/favicon-16x16.png sizes=16x16>
<meta name=generator content="Hugo 0.93.3">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Continuous aggregation in Kafka Streams","image":"https://leandro.ordonez.tech","datePublished":"2019-10-17T10:45:27+02:00","dateModified":"2019-10-17T10:45:27+02:00","author":{"@type":"Person","name":"Leandro Ordóñez Ante"},"mainEntityOfPage":{"@type":"WebPage"},"publisher":{"@type":"Organization","name":"Leandro Ordóñez Ante","logo":{"@type":"ImageObject","url":"https://leandro.ordonez.tech/images/avatar.jpg"}},"description":"Lago el Bolsón in Popayán, Colombia, my home town :)\n  In this post I show a method to address the computation of the arithmetic mean of an stream of values (say sensor readings) using the Kafka Streams DSL. The estimation of the average in a stream processing setting implies keeping track of other two measurements, namely the count of incoming records and the sum of their corresponding values.","keywords":["kafka","streams","aggregation"]}</script>
</head><body class=colorscheme-light>
<main class=wrapper>
<nav class=navigation>
<section class=container>
<a class=navigation-title href=https://leandro.ordonez.tech/es-co>
Leandro Ordóñez Ante
</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fas fa-bars"></i></label>
<ul class=navigation-list>
<li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/ideas/>Scrapbook</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/publications/>Publicaciones</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/phd/>PhD</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/about/>Sobre mi</a>
</li><li class="navigation-item menu-separator">
<span>|</span>
</li><li class=navigation-item>
<a href=https://leandro.ordonez.tech/ideas/continuous-aggregation-kafka-streams/>English</a>
</li></ul></section></nav><div class=content>
<section class="container post">
<article>
<header>
<div class=post-title>
<h1 class=title>Continuous aggregation in Kafka Streams</h1></div><div class=post-meta>
<div class=date>
<span class=posted-on>
<i class="fas fa-calendar"></i>
<time datetime=2019-10-17T10:45:27+02:00>
October 17, 2019
</time>
</span>
<span class=reading-time>
<i class="fas fa-clock"></i>
2-minute read
</span>
</div><div class=categories>
<i class="fas fa-folder"></i>
<a href=https://leandro.ordonez.tech/es-co/categories/data-management/>Data management</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/categories/iot/>IoT</a></div><div class=tags>
<i class="fas fa-tag"></i>
<a href=https://leandro.ordonez.tech/es-co/tags/kafka/>kafka</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/streams/>streams</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/aggregation/>aggregation</a></div></div></header><div>
<figure><img src=https://leandro.ordonez.tech/images/ideas/lago-bolson.jpg alt="Lago el Bolsón in Popayán, Colombia, my home town :)"><figcaption>
<p>Lago el Bolsón in Popayán, Colombia, my home town :)</p></figcaption></figure><p>In this post I show a method to address the computation of the arithmetic mean of an stream of values (say sensor readings) using the Kafka Streams DSL. The estimation of the average in a stream processing setting implies keeping track of other two measurements, namely the count of incoming records and the sum of their corresponding values. Let&rsquo;s consider a Kafka streams application consuming messages from a topic to which the readings of multiple temperature sensors are being posted (<code>temperature-readings</code>). The messages from said topic are keyed by the sensor ID, and we want to compute the rolling average of the temperature sensed by each device.</p><p>Let&rsquo;s first create a <code>KGroupedStream</code> to group the sensor readings according to their corresponding sensor ID:</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1.js?file=KafkaStreamsAggregator_1.java"></script>
<p>Now we can use the <code>KGroupedStream::aggregate</code> method to compute the rolling average on the <code>perSensorStream</code> we got above. But before this, according to the Kafka <a href=https://docs.confluent.io/current/streams/javadocs/org/apache/kafka/streams/kstream/KGroupedStream.html#aggregate-org.apache.kafka.streams.kstream.Initializer-org.apache.kafka.streams.kstream.Aggregator->documentation</a> this method requires an <code>Initializer</code> and an <code>Aggregator</code> as arguments:</p><blockquote>
<p>The specified <code>Initializer</code> is applied once directly before the first input record is processed to provide an initial intermediate aggregation result that is used to process the first record. The specified <code>Aggregator</code> is applied for each input record and computes a new aggregate using the current aggregate (or for the very first record using the intermediate aggregation result provided via the Initializer) and the record&rsquo;s value. Thus, aggregate(Initializer, Aggregator) can be used to compute aggregate functions like count (c.f. count()).</p></blockquote><p>Let&rsquo;s create a POJO to provide such initial aggregation and to hold the intermediate aggregation values:</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1.js?file=AggregateTuple.java"></script>
<p>Now we need to provide an implementation of the <code>apply</code> method for the <code>Aggregator</code> argument, which would be in charge of computing a new aggregate from the <code>key</code> and <code>value</code> of an incoming record and the current <code>aggregate</code> of the same key:</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1.js?file=KafkaStreamsAggregator_2.java"></script>
<p>We can finally call the <code>aggregate</code> method on the <code>perSensorStream</code>:</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1.js?file=KafkaStreamsAggregator_3.java"></script>
<p>Below you can find the relevant code for the aggregation method outlined in this post.</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1.js?file=KafkaStreamsAggregator.java"></script>
<p>I didn&rsquo;t include the code for handling serialization in this post, but you can find it here: <a href=https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1#file-jsonpojoserializer-java>JsonPOJOSerializer</a> and <a href=https://gist.github.com/LeandroOrdonez/aadca09b9aaa41a3b61c41796f3581d1#file-jsonpojodeserializer-java>JsonPOJODeserializer</a>.</p></div><footer>
<div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//personal-site-of-leandro-ordonez.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script>
<noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a>
</footer></article></section></div><footer class=footer>
<section class=container>
<p>Investigo mecanismos para el acceso a Big Data de manera rápida, eficiente y confiable</p>©
2022
Leandro Ordóñez Ante
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.
</section></footer></main><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-149589206-1","auto"),ga("send","pageview"))</script>
</body></html>