<!doctype html><html lang=es-co>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=content-language content="es-co">
<meta name=author content="Leandro Ordóñez Ante">
<meta name=description content="Data Pipeline by xkcd.com
  In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">
<meta name=keywords content="blog,desarrollador,personal">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Interactive querying for spatiotemporal data with Kafka Streams">
<meta name=twitter:description content="Data Pipeline by xkcd.com
  In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">
<meta property="og:title" content="Interactive querying for spatiotemporal data with Kafka Streams">
<meta property="og:description" content="Data Pipeline by xkcd.com
  In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://leandro.ordonez.tech/es-co/ideas/interactive-querying-kafka-streams/"><meta property="article:section" content="ideas">
<meta property="article:published_time" content="2020-04-05T14:10:33+01:00">
<meta property="article:modified_time" content="2020-04-05T14:10:33+01:00">
<base href=https://leandro.ordonez.tech/es-co/ideas/interactive-querying-kafka-streams/>
<title>
Interactive querying for spatiotemporal data with Kafka Streams · Leandro Ordóñez Ante
</title><link rel=canonical href=https://leandro.ordonez.tech/es-co/ideas/interactive-querying-kafka-streams/>
<link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel=stylesheet>
<link rel=stylesheet href=https://use.fontawesome.com/releases/v5.13.0/css/all.css integrity=sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V crossorigin=anonymous>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin=anonymous>
<link rel=stylesheet href=https://leandro.ordonez.tech/css/coder.min.28d751104f30c16da1aa1bb04015cbe662cacfe0d1b01af4f2240ad58580069c.css integrity="sha256-KNdREE8wwW2hqhuwQBXL5mLKz+DRsBr08iQK1YWABpw=" crossorigin=anonymous media=screen>
<link rel=stylesheet href=https://leandro.ordonez.tech/css/custom.css>
<link rel=icon type=image/png href=https://leandro.ordonez.tech/images/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=https://leandro.ordonez.tech/images/favicon-16x16.png sizes=16x16>
<meta name=generator content="Hugo 0.93.3">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Interactive querying for spatiotemporal data with Kafka Streams","image":"https://leandro.ordonez.tech","datePublished":"2020-04-05T14:10:33+01:00","dateModified":"2020-04-05T14:10:33+01:00","author":{"@type":"Person","name":"Leandro Ordóñez Ante"},"mainEntityOfPage":{"@type":"WebPage"},"publisher":{"@type":"Organization","name":"Leandro Ordóñez Ante","logo":{"@type":"ImageObject","url":"https://leandro.ordonez.tech/images/avatar.jpg"}},"description":"Data Pipeline by xkcd.com\n  In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.","keywords":["kafka","streams","querying","iot","sensor","data"]}</script>
</head><body class=colorscheme-light>
<main class=wrapper>
<nav class=navigation>
<section class=container>
<a class=navigation-title href=https://leandro.ordonez.tech/es-co>
Leandro Ordóñez Ante
</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fas fa-bars"></i></label>
<ul class=navigation-list>
<li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/ideas/>Scrapbook</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/publications/>Publicaciones</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/phd/>PhD</a>
</li><li class=navigation-item>
<a class=navigation-link href=https://leandro.ordonez.tech/es-co/about/>Sobre mi</a>
</li><li class="navigation-item menu-separator">
<span>|</span>
</li><li class=navigation-item>
<a href=https://leandro.ordonez.tech/ideas/interactive-querying-kafka-streams/>English</a>
</li></ul></section></nav><div class=content>
<section class="container post">
<article>
<header>
<div class=post-title>
<h1 class=title>Interactive querying for spatiotemporal data with Kafka Streams</h1></div><div class=post-meta>
<div class=date>
<span class=posted-on>
<i class="fas fa-calendar"></i>
<time datetime=2020-04-05T14:10:33+01:00>
April 5, 2020
</time>
</span>
<span class=reading-time>
<i class="fas fa-clock"></i>
3-minute read
</span>
</div><div class=categories>
<i class="fas fa-folder"></i>
<a href=https://leandro.ordonez.tech/es-co/categories/programming/>Programming</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/categories/data-management/>Data management</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/categories/stream-processing/>Stream processing</a></div><div class=tags>
<i class="fas fa-tag"></i>
<a href=https://leandro.ordonez.tech/es-co/tags/kafka/>kafka</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/streams/>streams</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/querying/>querying</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/iot/>iot</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/sensor/>sensor</a>
<span class=separator>•</span>
<a href=https://leandro.ordonez.tech/es-co/tags/data/>data</a></div></div></header><div>
<figure class=center><img src=https://imgs.xkcd.com/comics/data_pipeline.png alt="Data Pipeline by xkcd.com"><figcaption>
<p>Data Pipeline by <a href=https://xkcd.com/2054/>xkcd.com</a></p></figcaption></figure><p>In a <a href=https://leandro.ordonez.tech/ideas/continuous-aggregation-kafka-streams/>previous post</a> we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you <a href=https://github.com/LeandroOrdonez/kafka-streams-pipeline><code>kafka-streams-pipeline</code></a>, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized <code>KTable</code>, by incorporating the spatial and temporal dimensions of the sensor data to the analysis. To understand how this application works, let’s first get back to the <code>temperature-readings</code> topic from the previous post. In this topic the feed of temperature measurements made by multiple sensors is being posted. The following is an excerpt of the measurements registered in <code>temperature-readings</code>:</p><script type=application/javascript src="https://gist.github.com/LeandroOrdonez/04eb02301d15f9af942cf76faa9e99c3.js?file=temperature_readings.json"></script>
<p>Each JSON object from the list above represents a temperature reading taken by a given sensor. Notice the <code>timestamp</code> and <code>geohash</code> fields, which hold the information about the time and the location of each measurement. In case you are not familiar with the concept of geohashing, it is basically an encoding mechanism created by Gustavo Niemeyer in 2008, that allows reducing a two-dimensional longitude, latitude pair into a single alphanumeric string (in base32 format), where each subsequent character adds precision to the location. So, for instance, the geohash <code>u155mz82dv33</code> corresponds to the longitude, latitude pair <code>(4.47189873, 51.23760204)</code>. The idea is to enable interactive (low-latency) queries that support typical visual exploratory analysis tasks on top of the spatiotemporal data being posted to <code>temperature-readings</code>, by leveraging some appealing features of geohashes such as its inherent hierarchical structure, which recursively subdivides geospatial areas into 32 cells or tiles at each level (character)<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, as you can see in the diagram below.</p><figure class=img60><img src=https://leandro.ordonez.tech/images/ideas/geohash.jpg alt="Geohashes by Movable Type Scripts"><figcaption>
<p>Geohashes by <a href=https://www.movable-type.co.uk/scripts/geohash.html>Movable Type Scripts</a></p></figcaption></figure><p>This way, by truncating the <code>geohash</code> of each of the incoming readings to a certain number characters, we can set up a grid for partitioning the temperature data in the spatial dimension, and perform continuous aggregation on each of the resulting partitions. The same principle can be applied in the temporal dimension by truncating the <code>timestamp</code> of each reading to a certain unit of time, laying out a temporal partitioning schema that arranges data into time bins of a fixed width (for instance, <em>minutely</em>, <em>hourly</em>, or <em>daily</em> bins).</p><p>The application focuses on serving two types of queries: (<em>1</em>) <strong>Historical queries</strong>, namely those asking how the temperature has evolved along a given geospatial region, over a certain period of time; and (<em>2</em>) <strong>Snapshot queries</strong> which provide a time-slice view of the temperature for a specific moment in time.</p><figure class=center><img src=https://leandro.ordonez.tech/images/ideas/historical-snapshot-queries.jpg alt="Historical and Snapshot queries"><figcaption>
<p>Historical and Snapshot queries</p></figcaption></figure><p>Below you can see a schematics showing the structure of the stream processing pipeline at the core of the application discussed in this post.</p><figure class=img60><img src=https://leandro.ordonez.tech/images/ideas/architecture-kstreams-querying.jpg alt="Stream processing pipeline for interactive querying with Kafka Streams"><figcaption>
<p>Stream processing pipeline for interactive querying with Kafka Streams</p></figcaption></figure><p>As you can see in the diagram above, it is possible to deploy multiple stream processors, each one hosting an instance of the state store where one fraction of the global application state is persisted. In consequence, in this distributed setup queries are computed by combining the result sets obtained from each processor:</p><figure class=center><img src=https://leandro.ordonez.tech/images/ideas/dist-query-processing.jpg alt="Distributed query resolution"><figcaption>
<p>Distributed query resolution</p></figcaption></figure><p>The source code of this application is available on <a href=https://github.com/LeandroOrdonez/kafka-streams-pipeline>github</a>. You can deploy the entire pipeline (including an application for generating syntethic temperature values, discussed in a <a href=https://leandro.ordonez.tech/ideas/mocking-sensor-data-generator/>recent post</a>) on your local machine using Docker. Just clone the repository and follow the instructions on the <code>README.md</code> file. Hope you find it useful! :)</p><section class=footnotes role=doc-endnotes>
<hr>
<ol>
<li id=fn:1 role=doc-endnote>
<p><a href=https://www.movable-type.co.uk/scripts/geohash.html>Here</a> you can find a more detailed explanation on geohashes.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer>
<div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//personal-site-of-leandro-ordonez.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script>
<noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a>
</footer></article></section></div><footer class=footer>
<section class=container>
<p>Investigo mecanismos para el acceso a Big Data de manera rápida, eficiente y confiable</p>©
2022
Leandro Ordóñez Ante
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.
</section></footer></main><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-149589206-1","auto"),ga("send","pageview"))</script>
</body></html>