<!DOCTYPE html>
<html lang="es-co">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>
  Interactive querying for spatiotemporal data with Kafka Streams · Leandro Ordóñez Ante
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Leandro Ordóñez Ante">
<meta name="description" content="Data Pipeline by xkcd.com
In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">
<meta name="keywords" content="blog,desarrollador,personal">
<meta name="fediverse:creator" content="" />


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Interactive querying for spatiotemporal data with Kafka Streams">
  <meta name="twitter:description" content="Data Pipeline by xkcd.com
In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">

<meta property="og:url" content="http://localhost:1313/es-co/ideas/interactive-querying-kafka-streams/">
  <meta property="og:site_name" content="Leandro Ordóñez Ante">
  <meta property="og:title" content="Interactive querying for spatiotemporal data with Kafka Streams">
  <meta property="og:description" content="Data Pipeline by xkcd.com
In a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.">
  <meta property="og:locale" content="es_co">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ideas">
    <meta property="article:published_time" content="2020-04-05T14:10:33+01:00">
    <meta property="article:modified_time" content="2020-04-05T14:10:33+01:00">
    <meta property="article:tag" content="Kafka">
    <meta property="article:tag" content="Streams">
    <meta property="article:tag" content="Querying">
    <meta property="article:tag" content="Iot">
    <meta property="article:tag" content="Sensor">
    <meta property="article:tag" content="Data">




<link rel="canonical" href="http://localhost:1313/es-co/ideas/interactive-querying-kafka-streams/">


<link rel="preload" href="http://localhost:1313/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="http://localhost:1313/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="http://localhost:1313/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="http://localhost:1313/css/coder.css" media="screen">






  
    
    
    <link rel="stylesheet" href="http://localhost:1313/css/coder-dark.css" media="screen">
  



 




<link rel="icon" type="image/svg+xml" href="http://localhost:1313/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="http://localhost:1313/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:1313/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="http://localhost:1313/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/images/apple-touch-icon.png">

<link rel="manifest" href="http://localhost:1313/site.webmanifest">
<link rel="mask-icon" href="http://localhost:1313/images/safari-pinned-tab.svg" color="#5bbad5">









  <script type="application/ld+json">
    
    {
      "@context": "https://schema.org",
      "@type": "BlogPosting",
      "headline": "Interactive querying for spatiotemporal data with Kafka Streams",
      "image": "http://localhost:1313/",
      "datePublished": "2020-04-05T14:10:33+01:00",
      "dateModified": "2020-04-05T14:10:33+01:00",
      "author": {
        "@type": "Person",
        "name": "Leandro Ordóñez Ante"
      },
      "mainEntityOfPage": { "@type": "WebPage" },
      "publisher": {
        "@type": "Organization",
        "name": "Leandro Ordóñez Ante",
        "logo": {
          "@type": "ImageObject",
          "url": "https://leandro.ordonez.tech/images/avatar.jpg"
        }
      },
      "description": "Data Pipeline by xkcd.com\nIn a previous post we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you kafka-streams-pipeline, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized KTable, by incorporating the spatial and temporal dimensions of the sensor data to the analysis.",
      "keywords": ["kafka", "streams", "querying", "iot", "sensor", "data"]
    }
    
    </script>
</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="http://localhost:1313/es-co/">
      Leandro Ordóñez Ante
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="http://localhost:1313/es-co/ideas/">Scrapbook</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="http://localhost:1313/es-co/publications/">Publicaciones</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="http://localhost:1313/es-co/phd/">PhD</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="http://localhost:1313/es-co/about/">Sobre mi</a>
            </li>
          
        
        
          
          
          
            
              
                <li class="navigation-item menu-separator">
                  <span>|</span>
                </li>
                
              
              <li class="navigation-item">
                <a href="http://localhost:1313/ideas/interactive-querying-kafka-streams/">English</a>
              </li>
            
          
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://localhost:1313/es-co/ideas/interactive-querying-kafka-streams/">
              Interactive querying for spatiotemporal data with Kafka Streams
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2020-04-05T14:10:33&#43;01:00">
                abril 5, 2020
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              3-minute read
            </span>
          </div>
          
          <div class="categories">
  <i class="fa-solid fa-folder" aria-hidden="true"></i>
    <a href="http://localhost:1313/es-co/categories/programming/">Programming</a>
      <span class="separator">•</span>
    <a href="http://localhost:1313/es-co/categories/data-management/">Data Management</a>
      <span class="separator">•</span>
    <a href="http://localhost:1313/es-co/categories/stream-processing/">Stream Processing</a></div>

          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/kafka/">Kafka</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/streams/">Streams</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/querying/">Querying</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/iot/">Iot</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/sensor/">Sensor</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="http://localhost:1313/es-co/tags/data/">Data</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <figure class="center"><img src="https://imgs.xkcd.com/comics/data_pipeline.png"
    alt="Data Pipeline by xkcd.com"><figcaption>
      <p>Data Pipeline by <a href="https://xkcd.com/2054/"  class="external-link" target="_blank" rel="noopener">xkcd.com</a></p>
    </figcaption>
</figure>

<p>In a <a href="https://leandro.ordonez.tech/ideas/continuous-aggregation-kafka-streams/"  class="external-link" target="_blank" rel="noopener">previous post</a> we explored a method for performing continuous aggregation on a stream of sensor readings using the Kafka Streams DSL. This time I want to share with you <a href="https://github.com/LeandroOrdonez/kafka-streams-pipeline"  class="external-link" target="_blank" rel="noopener"><code>kafka-streams-pipeline</code></a>, a Kafka Streams application that leverages said continuous aggregation method and defines a complete stream processing pipeline, which enables querying the continuous data summaries stored into a materialized <code>KTable</code>, by incorporating the spatial and temporal dimensions of the sensor data to the analysis. To understand how this application works, let’s first get back to the <code>temperature-readings</code> topic from the previous post. In this topic the feed of temperature measurements made by multiple sensors is being posted. The following is an excerpt of the measurements registered in <code>temperature-readings</code>:</p>
<script src="https://gist.github.com/LeandroOrdonez/04eb02301d15f9af942cf76faa9e99c3.js?file=temperature_readings.json"></script>

<p>Each JSON object from the list above represents a temperature reading taken by a given sensor. Notice the <code>timestamp</code> and <code>geohash</code> fields, which hold the information about the time and the location of each measurement. In case you are not familiar with the concept of geohashing, it is basically an encoding mechanism created by Gustavo Niemeyer in 2008, that allows reducing a two-dimensional longitude, latitude pair into a single alphanumeric string (in base32 format), where each subsequent character adds precision to the location. So, for instance, the geohash <code>u155mz82dv33</code> corresponds to the longitude, latitude pair <code>(4.47189873, 51.23760204)</code>. The idea is to enable interactive (low-latency) queries that support typical visual exploratory analysis tasks on top of the spatiotemporal data being posted to <code>temperature-readings</code>, by leveraging some appealing features of geohashes such as its inherent hierarchical structure, which recursively subdivides geospatial areas into 32 cells or tiles at each level (character)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, as you can see in the diagram below.</p>
<figure class="img60"><img src="http://localhost:1313/images/ideas/geohash.jpg"
    alt="Geohashes by Movable Type Scripts"><figcaption>
      <p>Geohashes by <a href="https://www.movable-type.co.uk/scripts/geohash.html"  class="external-link" target="_blank" rel="noopener">Movable Type Scripts</a></p>
    </figcaption>
</figure>

<p>This way, by truncating the <code>geohash</code> of each of the incoming readings to a certain number characters, we can set up a grid for partitioning the temperature data in the spatial dimension, and perform continuous aggregation on each of the resulting partitions. The same principle can be applied in the temporal dimension by truncating the <code>timestamp</code> of each reading to a certain unit of time, laying out a temporal partitioning schema that arranges data into time bins of a fixed width (for instance, <em>minutely</em>, <em>hourly</em>, or <em>daily</em> bins).</p>
<p>The application focuses on serving two types of queries: (<em>1</em>) <strong>Historical queries</strong>, namely those asking how the temperature has evolved along a given geospatial region, over a certain period of time; and (<em>2</em>) <strong>Snapshot queries</strong> which provide a time-slice view of the temperature for a specific moment in time.</p>
<figure class="center"><img src="http://localhost:1313/images/ideas/historical-snapshot-queries.jpg"
    alt="Historical and Snapshot queries"><figcaption>
      <p>Historical and Snapshot queries</p>
    </figcaption>
</figure>

<p>Below you can see a schematics showing the structure of the stream processing pipeline at the core of the application discussed in this post.</p>
<figure class="img60"><img src="http://localhost:1313/images/ideas/architecture-kstreams-querying.jpg"
    alt="Stream processing pipeline for interactive querying with Kafka Streams"><figcaption>
      <p>Stream processing pipeline for interactive querying with Kafka Streams</p>
    </figcaption>
</figure>

<p>As you can see in the diagram above, it is possible to deploy multiple stream processors, each one hosting an instance of the state store where one fraction of the global application state is persisted. In consequence, in this distributed setup queries are computed by combining the result sets obtained from each processor:</p>
<figure class="center"><img src="http://localhost:1313/images/ideas/dist-query-processing.jpg"
    alt="Distributed query resolution"><figcaption>
      <p>Distributed query resolution</p>
    </figcaption>
</figure>

<p>The source code of this application is available on <a href="https://github.com/LeandroOrdonez/kafka-streams-pipeline"  class="external-link" target="_blank" rel="noopener">github</a>. You can deploy the entire pipeline (including an application for generating syntethic temperature values, discussed in a <a href="https://leandro.ordonez.tech/ideas/mocking-sensor-data-generator/"  class="external-link" target="_blank" rel="noopener">recent post</a>) on your local machine using Docker. Just clone the repository and follow the instructions on the <code>README.md</code> file. Hope you find it useful! :)</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.movable-type.co.uk/scripts/geohash.html"  class="external-link" target="_blank" rel="noopener">Here</a> you can find a more detailed explanation on geohashes.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script>
  window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "personal-site-of-leandro-ordonez" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    
    document.addEventListener('themeChanged', function (e) { 
        if (document.readyState == 'complete') {
          DISQUS.reset({ reload: true, config: disqus_config });
        }
    });
</script>
        
        
        
        

        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2024
     Leandro Ordóñez Ante 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="http://localhost:1313/js/coder.js"></script>
  

  

  


  
  



  

  

  

  

  

  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7HZJ3L2M6V"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7HZJ3L2M6V');
</script>


  

  

  

  

  

  

  
</body>

</html>
